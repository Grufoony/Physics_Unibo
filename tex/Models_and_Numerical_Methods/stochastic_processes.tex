\begin{definition}
    A \textbf{stochastic process} is an infinite sequence of random variables $X_n$ with values in $\mathcal{A}$ defined by the $k^\text{th}$ order joint distribution:
    \begin{equation*}
        \mu_k\left(a_1^k\right) = \mathbb{P}\left(X_1^k = a_1^k\right) \ \ a_1^k \in \mathcal{A}
    \end{equation*}
\end{definition}
We need also a consistency condition:
\begin{equation*}
    \mu_t\left(a_1^t\right) = \sum_{a_0 \in \mathcal{A}} \mu_{t+1}\left(a_0^t\right) = \sum_{a_{t+1} \in \mathcal{A}} \mu_{t+1}\left(a_1^{t+1}\right)
\end{equation*}
Equivalently, we can define a stochastic process through the conditional probability
\begin{equation*}
    \mu\left(a_t \vert a_1^{t-1}\right) = \frac{\mu_t\left(a_1^t\right)}{\mu_{t-1}\left(a_1^{t-1}\right)}
\end{equation*}
The $\mu_k$ are called \textbf{marginals} and, in order to be a probability, they must satisfy the normalization condition
\begin{equation*}
    \sum_{a_1^k \in \mathcal{A}} \mu_k\left(a_1^k\right) = 1
\end{equation*}
We notice that this sum is exponentially growing in $k$, so it's impossible to approximate the measure.
\begin{definition}
    A stochastic process is \textbf{stationary} if
    \begin{equation*}
        \mu\left(a_1^k\right) = \mu\left(a_{t+1}^{t+k}\right) \ \ \forall a_1^\infty \in \mathcal{A}^\mathbb{N}
    \end{equation*}
\end{definition}
\begin{definition}
    An \textbf{information source} is a stationary, ergodic, stochastic process.
\end{definition}
\begin{definition}
    A process or a source is a \textbf{shift-invariant Borel probability measure} $\mu$ on the topological space $\mathcal{A}^\mathbb{Z}$ of doubly-infinite sequences $x = \left\{x_n\right\}_{n \in \mathbb{Z}}$, drawn from a finite (i.e. countable) alphabet $\mathcal{A}$
\end{definition}
Furthermore, it is trivial that we can write any standard cylinder as
\begin{equation*}
    \left[x_1^t\right] = \sqcup_{a \in \mathcal{A}} \left[x_1, \ldots, x_t, a\right]
\end{equation*}
It's easy to check that
\begin{equation*}
    \mu \in \mathcal{P}_I\left({\Omega}\right) \ \vert \ \mu \circ \sigma^{-1} = \mu \Leftrightarrow \sum_{a \in \mathcal{A}} \mu_{t+1}\left(a, x_1, \ldots, x_t\right) = \mu_t\left(x_1^t\right)
\end{equation*}
Neural networks are heuristically approximating $\mu$.

\begin{theorem}[Kolmogorov representation theorem]
    If $\left\{\mu_n\right\}$ is a sequence of measure defining a process then there is a unique Borel probability measure $\mu$ on $\mathcal{A}^\infty$ such that, $\forall k \geq 1$ and $\forall \left[a_1^k\right]$ cylinder
    \begin{equation*}
        \mu\left(\left[a_1^k\right]\right) = \mu_k\left(a_1^k\right)
    \end{equation*}
\end{theorem}

\subsection{Markov's Models}
Markov's model is a stochastic model used to model pseudo-randomly changing systems. In a Markov's process the \emph{n} element probability depends only on previous \emph{k}-elements
\begin{equation}
\mu\left(x_{n}\ \vert\ x_{0}, x_{1}, \dots, x_{n-1}\right):=\mu\left(x_{n}\ \vert\ x_{k}, x_{k+1}, \dots, x_{n-1}\right)
\end{equation}

A Markov's chain is a Markov's process where the \emph{n} element depends only on the current state (\emph{n-1} element). For this reason a Markov's chain is a no memory process.
\begin{equation}
\mu\left(x_{n}\ \vert\ x_{0}, x_{1}, \dots, x_{n-1}\right):=\mu\left(x_{n}\ \vert\ x_{n-1}\right)
\end{equation}

We can define a \emph{Markov's measure}. Let's call $\mathbf{p}=\left(p_{1},\ p_{2},\dots ,\ p_{l}\right)$ the probability vector that a character of the alphabet \mathcal{A} is extracted and $P=\left[p_{ij}\right]$ the $l\times l$ matrix that describe the probability than the \emph{j} character is extracted when the privious one is the \emph{i}. We know that \mathbf{p} is normalized and $P$ is a stochastic matrix
\[p_{j}\geq 0\quad \sum_{j=1}^{l}p_{j}=1\qquad\sum_{h=1}^{j}p_{ij}=1\ \forall i\]
Since $P$ is stochastic it has the uniti vector as eighenvector with $1$ as eighenvalue. So for the \emph{Person-Frobenius theorem} all the eighenvalues are contained inside the complex circle with radius $1$.
We say that \mathbf{p} is \emph{invariant} if it's a P's eighenvector. We can define for all $n$ the \emph{Markov's measure}
\begin{equation}
\mu_{â€¢}\left(
\end{equation}


\subsection{Hidden Markov's Models}